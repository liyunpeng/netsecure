一个broker就是一台运行kakfa的服务的主机
 一个主题有多个分区，一个分区有多个副本， 每个副本在不同的broker上， 
每个分区的副本中有一个是leader副本，其他都是folloer副本
由于副本会分布在不同的主机上， 

生产者在把消息发给分区时， 会先发送到leader副本，然后再同步到其他副本， 
kafka会把消息

一个分区有副本组 

 ni 切片和空切片在使用上没有区别， 因为都可以 做apppend, 
数据库字符集必须在开始的时候设置好， 如果已经存入了数据， 

隔离级别：
事务A如果看到事务B还没提交的中间数据， 就是脏读
为解决这个问题， 就限定事务A只能读到事务B的已经提交的数据， 
这个措施是中隔离， 就叫做读已提交隔离， 即把其他事务未提交的数据隔离除外。读已提交， 英文为read commited, 所以简称RC隔离级别
 ---------------
脏读接解决了， 
现在又来个问题：
事务A在一行数据期间， 这一行数据正在被事务B修改， 但事务B没提交这一行。
事务A读完了之后， 事务B把这行的修改提交了，  事务A在第二次读这行数据时， 
和第一次读到的结果不同， 即两次读到的结果不同， 这个问题叫做不可重复读。 
为了解决这个不可重复读问题， 就有了一种隔离级别，规定在事务A在读该行时，如果其他事务要修改该行， 那么不允许开启这个事务， 已保证事务A对该行所有读操作的结果都是相同的， 这个隔离也因此得名， 叫做可重复读， 英文为repeadted read ， 简称RR隔离级别。 
RR级别是比较高的隔离级别， 会拖慢数据并发访问的速度。 所以innodb默认情况下， 不开启RR隔离级别， 相应的事务尽量保证只有一次读数据， 尽量少的动作， 尽量少的时间退出事务。 
除了RC， RR两个隔离级别， 还有读未提交， 即RU隔离， 和序列化隔离。 
读未提交隔离， 是没有任何措施的隔离， 等于没有隔离， 这个在myisam上默认使用， 所以myisam引擎数据访问比较。 
序列化隔离使得事务串行化，为了解决幻读问题， 因为串行化， 严重拖慢并发问速度， 所以很少使用。 
隔离的实现， 有两种实现方式， 
一种是锁， 
一种是mvcc。
锁按规模分为， 表锁，和行锁， 
表锁上锁块， 行锁上锁慢
锁按操作性质分， 读锁， 和写锁， 
读锁又叫共享锁， s锁
写锁又叫排他锁。 
innoddb 默认在读数据时， 不上锁， 在修改数据时， 上写锁。 
mysql可用tx 开启事务， 
可以在配置文件设置隔离级别， 
因为不用串行化隔离级别， 事务并发执行， 
事务内部对数据行的访问顺序尽量保持一致， 
上锁的代价是比较高， 导致其他事务一直阻塞在哪，又不睡眠， 又不释放cpu。 
锁基本就是现实中的锁， 一个人进入一间屋子， 上锁， 其他人都要在门口排队等待。 即不睡眠的盲等
mvcc实现隔离的方式， 每个事务都有版本号， 增加两个隐藏列， 分别一行数据
创建改行的事务的版本号， 和删除 该行事务的版本号。 
当前事务的版本号必须大于A版本号， 小于B版本号， A版本号相当于一个快照
事务操作的数据都都是在那个版本号时间点的数据， 
mvcc实现了事务的RR隔离级别。 

 
 casbin的enforce   在用gorm adapter时， 是一个完整的连接数据库
casbin的connnect配置可以写在tml文件里
数据库在创建时，要设置好字符集
否则有了数据后， 在改字符集须有好几个步骤， 
需要到处数据库表的结构， 然后再到处标的数据， 
然后再备份数据库， 
然后再删除原有数据库
然后 在重亲重新创建数据库， 导入之前备份的数据库
 所以在创建数据库时， 要设置好字符集 。 
不然casbin在连接数据库，在创建数据库表时， 会提示乱码错误
 排查问题， 要先看初始化log， 包括是否正确连接到mysql等第三方服务， 
 成功连接要现实出连接的结构， 
所有成功的连接应该能反应到log上。 

遇到问题时， 虽然最快的办法是设置断点， 但线上没有这个条件， 就的通过这些log, 而且需要一次性的解决问题，不给太多式样的机会， 因为需要狠毒偶的操作组合。 
 提交代码， 要尽量保持代码简洁，明了， 没有多余的动作。 
这样在排查时， 能少狠多的干扰， 
纳入casbin 的机制用户管理， 在传经用户时， 都要给用户绑定一个角色， 
结果会存放在casbin数据库表 里。 
每一行的开头代表该行在策略文件是匹配的 
如果是p, 表示是一个权限规则， 比如

p uri资源路径 ACTION动作， 

还有代表用户和角色绑定的g, 
比如
g 1 2 
表示将用户id为1的用户和角色id为2的角色绑定
这个绑定的动作在创建用户时 完成， 
所以gorm model在创建用户时， 就会绑定这个用户和角色。 
  
-----------------
生产这重要参数：
与吞吐率相关的：
缓冲区buffer.memrory： 消息会先发到缓冲区， 然后有专门的线程从缓冲区里取消息，发送出去。 
如果缓冲区满了， 生产这就会进入阻塞状态。  阻塞状态超过规定时间， 就会抛出异常。 

线程取出消息，也不是立即发送， 会积累一定数量一起发送， 即批量发送， 
batch规定到了多少的量后会发送。 

有两个参数决定是否发送， 一个是batch到了一定的量， 一个是到时间了 。 

生产者和broker之间是用socker连接的。 
生产这每发送一个消息， 都会收到borker的应答。 
正常情况， 发送一个消息， 收到这个消息的响应在发送下一个， 
max.in.flight.requests.per.connection设置为1， 即能规定这个行为， 发一个，收一个，再发下一个。 但是有时想提高发送率，可以再没有收到本消息的响应，就发第2个， 第3个， 最多发多少个，有参数确定， 
一般设置为5， 即一个消息没得到回应， 可以再最都发5个。 
这个参数设置大于1， 就有消息乱序的风险。 因为第一个消息没到broker, 第2个 消息就到broker了。  造成消息乱序。 
 保守设置1， 最大设置5. 

消息系统， 必须保证， 
1. 消息不丢失， 通过设置acks=all, 表示没有收到相应就重发， all表示消息同步到了所有副本。 是最高级别的持久化
2. 消息的重复 通过设置enable.idempotence=true。保证broker对消息处理的幂等性， 不管发多少个重复的消息， broker都保证只记录该消息一次。 
3. 消息的乱序， 这个由生产者的max.in.flight.requests.per.connection==1保证
4. 生产者发送消息的阻塞， 设置memmory.buffer大的缓冲区， 和大的batch。 提高发送的吞吐率。 


-----------------------------
前端优化：
webpack把整个前端打包成一个大文件， 完成一次下载所有需要的页面,js . css，都在一个文件列， 而不是等在用的时候，在区连接服务器。 
首页第一次访问， 会发送600多个请求， 
减少服务器请求是因为，每个请求都要经过dns寻址， 建立socket连接， 发送请求，等待服务器响应的漫长复杂过程。 而且浏览器并发请求的数量有上限， 
第二次之后只有10个请求， 
htpp缓存的越多越好， 越久越好。 
heaer设置一个较长的expirre时间， 
在区请求服务时， 会做一个比较， 
会和lastmodified比较， 如果和服务器没有差异， 服务会返回304相应， 表示客户端本地的缓存就可以用， 不用服务器传送的 。 
为了避免页面ui错误， 要先把css放在head里面， 而不是放在body里， 
因为body就开始渲染页面了， 而需要的css还没下载好。 
不涉及页面渲染的js可以放在页面尾部， 可以在页面渲染后在载入。 

js的优化，
1. 全局变量处在作用域链的顶端，  访问时用的查找次数最多。 所以一般用局部

缓冲区思想：
bufio 写文件
kafka生产者
滑动缓冲区思想： 
tcp： 

状态机：
tcp连接状态， 
kafka分区副本状态： 等待
 分布式 一致性要求：
redis分布式集群， kafka分布式集群， etcd集群， 

并发：
携程 携程池， 数据库谅解池， redis服务等各种服务的连接池


异步思想
为了保证消息的有序性， 生产者应该指定哪个分区， 而且不曾换分区， 
分区与分区之间是并行的， 所以消息如果有顺序的要求， 就不能发送到不同的分区。 
生产者要
设置每个消息要接收到确认消息同步到分区的所有副本的ack响应
要指定为接收到响应， 能继续发送的消息数为1， 
  

tcp: 
