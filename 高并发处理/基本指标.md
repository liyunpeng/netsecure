高并发架构相关概念
####　　并发：
在操作系统中，是指一个时间段中有几个程序都处于已启动运行到运行完毕之间，且这几个程序都是在同一个处理机上运行，但任一个时刻点上只有一个程序在处理机上运行；在互联网时代，所讲的并发，高并发通常是指并发访问，也就是在某个时间点，有多少个访问同时到来。

通常一个系统的日PV在千万以上，有可能是一个高并发的系统。
有的公司完全不走技术路线，全靠机器堆，这不在讨论范围内。
　　
#### QPS
每秒钟请求或者查询的数量，在互联网领域，指每秒响应请求数(指HTTP请求)；并发连接数是系统同时处理的请求数量
　　
#### 吞吐量
单位时间内处理的请求数量(通常由QPS与并发数决定)
　　
#### 响应时间
从请求发出到收到响应花费的时间。例如系统处理一个HTTP请求需要100ms。
　　
####  PV
综合浏览量(page view)，即页面浏览量或者点击量，一个访客在24小时内访问的页面数量；同一个人浏览网站同一页面，只记作一次PV
　　
#### UV
独立访客(unique visitor)，即一定时间范围内相同访客多次访问网站，只计算为一个独立访客
　　
#### 带宽：
计算带宽大小需关注两个指标，峰值流量和页面的平均大小
　　
#### 日网站带宽
日网站带宽=PV/统计时间(换算到s)*平均页面大小(单位KB)*8；峰值一般是平均值的倍数，根据实际情况来定
　　
#### 峰值每秒请求数 
峰值每秒请求数(QPS)=(总PV数*80%)/(6小时秒数*20%)；80%的访问量集中在20%的时间
　　
### 压力测试
测试能承受的最大并发，测试最大承受的QPS值
　　
#### 常用性能测试工具
ab，wrk，http_load，web_bench，siege，apache jmeter；ab全称是apache benchmark，apache官方推出的工具，创建多个并发访问线程，模拟多个访问者同时对某一trl地址进行访问，它的测试目标是基于url的，因此既可以用来测试apache的负载能力，也可以测试nginx，lighthttp，tomcat，IIS等其它web服务器的压力；ab的使用：模拟并发请求100次，总共请求5000次，ab -c 100 -n 5000 待测试网站；测试机器与被测试机器分开，不要对线上服务做压力测试，观察测试工具ab所在机器，以及被测试的前端机的CPU，内存，网络等都不超过最高限度的75%
　　
### QPS达到极限
随着QPS的增长，每个阶段需要根据实际情况来进行优化，优化的方案也与硬件条件、网络带宽息息相关；
* QPS达到50，可以称之为小型网站，一般的服务器就可以应付；

* QPS达到100，假设关系型数据库的每次请求在0.01s完成，假设单页面只有一个SQL查询，那么100QPS意味着1s完成100次请求，但是此时并不能保证数据库查询能完成100次，数据库缓存层，数据库的负载均衡；

* QPS达到800，假设使用百兆带宽，意味着网站出口的实际带宽是8M左右，假设每个页面只有10k，在这个并发条件下，百兆带宽已经吃完，CDN加速，负载均衡；

* QPS达到1000，假设使用memcache缓存数据库查询数据，每个页面对memcache的请求远大于直接对db的请求，memcache的悲观并发数在2w左右，但有可能在之前内网带宽已经吃光，表现出不稳定，静态HTML缓存；QPS达到2000，这个级别下，文件系统访问锁都成为了灾难，做业务分离，分布式存储

### 高并发解决方案案例
* 流量优化：防盗链处理
* 前端优化：减少HTTP请求，合并css或js，添加异步请求，启用浏览器缓存和文件压缩，CDN加速，建立独立图片服务器，
* 服务端优化：页面静态化，并发处理，队列处理
* 数据库优化：数据库缓存，分库分表，分区操作，读写分离，负载均衡
* web服务器优化：负载均衡，nginx反向代理，7,4层LVS软件